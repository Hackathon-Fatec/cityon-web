# -*- coding: utf-8 -*-
"""sentiment_analyser.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J_yM_xw_Z2i3BfyVhHJXy45aSKNbW3JP
"""

!pip install nltk
!pip install spacy
!python -m spacy download pt_core_news_sm

"""
Jo√£o Assalim
https://www.kaggle.com/datasets/augustop/portuguese-tweets-for-sentiment-analysis?select=NoThemeTweets.csv
"""

import pandas as pd
import numpy as np

import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import accuracy_score

import string

df = pd.read_csv('./olist.csv')
df = df.drop(["review_text", "review_text_tokenized", "polarity", "kfold_rating", "kfold_polarity", "original_index"], axis=1)
df = df[:40000]
df.head()

df["rating"] = np.where(df["rating"] < 3, 0, 1)

df.shape

df.isnull().sum()

df = df.dropna()

nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')

stop_words = nltk.corpus.stopwords.words('portuguese')

df.info()

tweets = df["review_text_processed"]
tokenization = [word_tokenize(text.lower()) for text in tweets]

lemmatizer = WordNetLemmatizer()

new_tweets = []

for phrase in tokenization:
  new_phrase = ""
  for token in phrase:
    if not str(token) in stop_words and not token in string.punctuation and "@" not in token and "http" not in token and len(token) > 1 and not token.isdigit():
      new_phrase += lemmatizer.lemmatize(str(token)) + " "
  new_tweets.append(new_phrase[:-1])

df["review_text_processed"] = new_tweets

vect_uni_idf = TfidfVectorizer(ngram_range=(1,1), use_idf=True, norm='l2', stop_words=stop_words)
text_vect_uni_idf = vect_uni_idf.fit_transform(df["review_text_processed"])

X_trainUIDF, X_testUIDF, y_trainUIDF, y_testUIDF = train_test_split(text_vect_uni_idf, df["rating"], test_size=0.2, random_state=42)

rfcidf = RandomForestClassifier()

rfcidf.fit(X_trainUIDF, y_trainUIDF)
y_predUIDF = rfcidf.predict(X_testUIDF)

import joblib
model_filename = 'sentiment_analyser_model.pkl'
joblib.dump(rfcidf, model_filename)

model_filename = 'sentiment_analyser_vect.pkl'
joblib.dump(vect_uni_idf, model_filename)